# bf-hackathon

## run project
```
poetry run python main.py
```

Mediapipe hands works for palm, thumbs up, peace, four
```
poetry run python models/mediapipe_hands.py -d -i data/four2.png
```


# Human-Robot Interaction Made Natural
Built by humor.io at Black Florest Hackathon, 9-11 May 2025

## ğŸš€ Overview
A proof-of-concept system that enables mobile robots to interact naturally with human workers using voice commands, hand gestures, and a simple user interface. Designed for real-time responsiveness and ease of use â€” no technical skills required.

## ğŸ¯ Problem Statement
In manufacturing environments, mobile robots are often rigidly controlled from centralized systems. This creates bottlenecks when tasks shift, leading to:

- Frequent interruptions in human workflow

- A frustrating user experience

- Decreased productivity

- Underutilization of robotic potential

## ğŸ’¡ Our Solution
- A multi-modal human-robot interaction interface that:

    - Uses voice recognition, hand gestures, and a web-based UI

    - Allows workers to guide robots naturally, on the spot

    - Requires zero programming or robotics knowledge

    - Runs in real-time and is fully demoable on a notebook


## ğŸ§  Core Features
âœ… Voice-controlled commands (e.g., "bring me beer")

âœ‹ Gesture recognition for contextual input

ğŸ–¥ï¸ Lightweight, web UI

ğŸ”„ Real-time feedback and status monitoring

ğŸ¤ Seamless integration with ROS2 and REST APIs

## ğŸ“¦ Models & ğŸ› ï¸ Tech Stack
Our system integrates a variety of cutting-edge models and open-source tools for real-time human-robot interaction:

**YOLOv8** â€“ for fast and accurate hand gesture detection

**Vosk** â€“ lightweight offline speech recognition (multilingual support)

**MediaPipe** â€“ for hand landmarks and gesture analysis

**ROS2** â€“ robot control and sensor communication

**OpenCV** â€“ for video processing and computer vision

**REST API** â€“ communication between modules and the robot

**Hardware**: SEW mobile robot (with RGB camera, laser scanner)


## ğŸŒ± Future Development
- Self-learning
- 3D Recognition
- Natural Communication
- Transition to Multiple Scenarios
- Simultaneous Multi-model Interaction

We believe robots should feel like helpful teammates â€” not more work. ğŸ™Œ

